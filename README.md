# ğŸ¤– AI Job-Candidate Matching System

An intelligent job-candidate matching system built with **NestJS** that leverages **Large Language Models (LLMs)**, **Retrieval Augmented Generation (RAG)**, and a **multi-agent architecture** to intelligently match job descriptions with candidate CVs.

---

## ğŸ–¼ï¸ System Overview Infographic

![How an AI Job Matching Engine Works](./infographic.png)

*The infographic above illustrates the complete flow: from PDF ingestion through LLM extraction, dual storage (SQL + Vector), dual-search matching strategy, multi-factor scoring algorithm, to final ranked results delivery.*

---

## ğŸ“‘ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
  - [System Architecture](#system-architecture)
  - [Agentic Architecture](#agentic-architecture)
  - [RAG Pipeline](#rag-pipeline)
- [Technology Stack](#-technology-stack)
- [Models and Methods](#-models-and-methods)
  - [Google Gemini 2.5 Flash Lite](#google-gemini-25-flash-lite)
  - [Text Embedding Model](#text-embedding-model)
  - [RAG with Qdrant](#rag-with-qdrant)
  - [Dual Search Strategy](#dual-search-strategy)
  - [Sophisticated Scoring Algorithm](#sophisticated-scoring-algorithm)
- [Dataset Description](#-dataset-description)
- [Setup Instructions](#-setup-instructions)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Configuration](#configuration)
  - [Running the Application](#running-the-application)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Deliverables](#-deliverables)
- [Authors](#-authors)

---

## ğŸ¯ Overview

This project implements an AI-powered job matching system that automatically:
1. **Ingests CVs/Resumes** from PDF files and extracts structured information
2. **Processes Job Descriptions** to understand requirements
3. **Matches Candidates to Jobs** using semantic similarity and structured queries
4. **Ranks Candidates** with a sophisticated multi-factor scoring algorithm

The system uses a **multi-agent architecture** where specialized agents handle different tasks, coordinated by an orchestrator agent.

---

## âœ¨ Features

- **ğŸ“„ PDF Processing**: Automatic extraction of text from CV and job description PDFs
- **ğŸ§  LLM-Powered Extraction**: Uses Google Gemini 2.5 Flash Lite for structured data extraction
- **ğŸ” Dual Search Strategy**: Combines SQL queries with semantic vector search
- **ğŸ“Š Sophisticated Scoring**: Multi-factor weighted scoring algorithm
- **ğŸš€ RESTful API**: Full CRUD operations with Swagger documentation
- **ğŸ³ Docker Support**: Easy deployment with Docker Compose
- **ğŸ“ˆ Scalable Architecture**: Modular design with NestJS

---

## ğŸ—ï¸ Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           NestJS Application                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   /api/candidate/*  â”‚   /api/job-offer/*  â”‚        Swagger Docs             â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   POST /load        â”‚   POST /match       â”‚        /docs                    â”‚
â”‚   POST /load_folder â”‚   POST /match-path  â”‚                                 â”‚
â”‚   GET /             â”‚   GET /             â”‚                                 â”‚
â”‚   GET /:id          â”‚   GET /:id          â”‚                                 â”‚
â”‚   DELETE /:id       â”‚   DELETE /:id       â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                           Service Layer                                      â”‚
â”‚          CandidateService              JobOfferService                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         AGENTIC LAYER                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                      OrchestratorAgent                               â”‚   â”‚
â”‚   â”‚                    (Central Task Router)                             â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚           â–¼                                         â–¼                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ CandidateIngestion    â”‚              â”‚   JobProcessing       â”‚          â”‚
â”‚   â”‚      Agent            â”‚              â”‚      Agent            â”‚          â”‚
â”‚   â”‚                       â”‚              â”‚                       â”‚          â”‚
â”‚   â”‚ â€¢ Parse PDFs          â”‚              â”‚ â€¢ Parse PDFs          â”‚          â”‚
â”‚   â”‚ â€¢ Extract data (LLM)  â”‚              â”‚ â€¢ Extract data (LLM)  â”‚          â”‚
â”‚   â”‚ â€¢ Generate embeddings â”‚              â”‚ â€¢ Execute dual search â”‚          â”‚
â”‚   â”‚ â€¢ Store to DB         â”‚              â”‚ â€¢ Calculate scores    â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                            TOOLS LAYER                                       â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ PostgresQuery   â”‚  â”‚  VectorSearch   â”‚  â”‚    MatchingGrade        â”‚     â”‚
â”‚   â”‚     Tool        â”‚  â”‚     Tool        â”‚  â”‚       Tool              â”‚     â”‚
â”‚   â”‚                 â”‚  â”‚                 â”‚  â”‚                         â”‚     â”‚
â”‚   â”‚ SQL filtering   â”‚  â”‚ Semantic search â”‚  â”‚ Sophisticated scoring   â”‚     â”‚
â”‚   â”‚ by skills, exp  â”‚  â”‚ via Qdrant      â”‚  â”‚ with weighted factors   â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          SERVICES LAYER                                      â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ LLMService  â”‚    â”‚ EmbeddingServiceâ”‚    â”‚   PdfParserService      â”‚     â”‚
â”‚   â”‚             â”‚    â”‚                 â”‚    â”‚                         â”‚     â”‚
â”‚   â”‚ Gemini 2.5  â”‚    â”‚ text-embedding  â”‚    â”‚   pdf-parse library     â”‚     â”‚
â”‚   â”‚ Flash Lite  â”‚    â”‚    -004         â”‚    â”‚                         â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         DATA LAYER                                           â”‚
â”‚                                                                              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚     PostgreSQL      â”‚         â”‚       Qdrant        â”‚             â”‚
â”‚         â”‚     (Port 5432)     â”‚         â”‚     (Port 6333)     â”‚             â”‚
â”‚         â”‚                     â”‚         â”‚                     â”‚             â”‚
â”‚         â”‚ â€¢ Candidates table  â”‚         â”‚ â€¢ candidates        â”‚             â”‚
â”‚         â”‚ â€¢ Jobs table        â”‚         â”‚   collection        â”‚             â”‚
â”‚         â”‚ â€¢ JSONB fields      â”‚         â”‚ â€¢ jobs collection   â”‚             â”‚
â”‚         â”‚ â€¢ Indexed queries   â”‚         â”‚ â€¢ 768-dim vectors   â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agentic Architecture

The system employs a **multi-agent architecture** with three main agents:

#### 1. OrchestratorAgent (Central Coordinator)
- **Role**: Task router and coordinator
- **Responsibilities**:
  - Receives tasks from API controllers
  - Routes tasks to appropriate worker agents
  - Handles errors and aggregates results
- **Supported Tasks**: `ingest_cv`, `ingest_folder`, `match_job`

#### 2. CandidateIngestionAgent (CV Processing)
- **Role**: Process CVs/resumes and store candidate data
- **Pipeline**:
  1. Parse PDF â†’ Extract raw text
  2. LLM Extraction â†’ Structured data (name, skills, experience)
  3. Summary Generation â†’ Search-optimized summary
  4. Embedding Generation â†’ 768-dimensional vector
  5. Dual Storage â†’ PostgreSQL + Qdrant

#### 3. JobProcessingAgent (Job Matching)
- **Role**: Process job descriptions and find matching candidates
- **Pipeline**:
  1. Parse PDF â†’ Extract job requirements
  2. LLM Extraction â†’ Structured requirements
  3. Save Job â†’ PostgreSQL + Qdrant
  4. Dual Search â†’ SQL + Vector search
  5. Score Calculation â†’ Sophisticated matching

### RAG Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG (Retrieval Augmented Generation) Flow                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INDEXING PHASE (CV Ingestion):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF CV    â”‚ -> â”‚  LLM        â”‚ -> â”‚  Embedding  â”‚ -> â”‚  Vector Store       â”‚
â”‚   Upload    â”‚    â”‚  Extraction â”‚    â”‚  Generation â”‚    â”‚  (Qdrant)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                                        â”‚
                          â–¼                                        â–¼
                   Structured Data                          768-dim Vector
                          â”‚                                        â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚   PostgreSQL    â”‚
                                      â”‚   (Metadata)    â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RETRIEVAL PHASE (Job Matching):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Job PDF    â”‚ -> â”‚  LLM        â”‚ -> â”‚          DUAL RETRIEVAL                 â”‚
â”‚  Upload     â”‚    â”‚  Extraction â”‚    â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                          â”‚           â”‚  â”‚ SQL Query   â”‚    â”‚ Vector      â”‚    â”‚
                          â–¼           â”‚  â”‚ (PostgreSQL)â”‚    â”‚ Search      â”‚    â”‚
                   Job Requirements   â”‚  â”‚             â”‚    â”‚ (Qdrant)    â”‚    â”‚
                          â”‚           â”‚  â”‚ Skills      â”‚    â”‚             â”‚    â”‚
                          â”‚           â”‚  â”‚ Experience  â”‚    â”‚ Semantic    â”‚    â”‚
                          â”‚           â”‚  â”‚ Filters     â”‚    â”‚ Similarity  â”‚    â”‚
                          â”‚           â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
                          â”‚           â”‚         â”‚                  â”‚           â”‚
                          â”‚           â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                          â”‚           â”‚                  â–¼                     â”‚
                          â”‚           â”‚         MERGE & SCORE                  â”‚
                          â”‚           â”‚                  â”‚                     â”‚
                          â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                              â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚ Ranked Results  â”‚
                                      â”‚ (Top 5)         â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Framework** | NestJS + TypeScript | Backend application framework |
| **LLM** | Google Gemini 2.5 Flash Lite | Structured data extraction |
| **Embeddings** | Google text-embedding-004 | 768-dimensional vectors |
| **Vector Database** | Qdrant | Semantic similarity search |
| **Relational Database** | PostgreSQL | Structured data storage |
| **ORM** | TypeORM | Database abstraction |
| **PDF Processing** | pdf-parse | PDF text extraction |
| **Validation** | Zod | Schema validation |
| **API Documentation** | Swagger/OpenAPI | Interactive API docs |
| **Containerization** | Docker Compose | Service orchestration |

---

## ğŸ§  Models and Methods

### Google Gemini 2.5 Flash Lite

**Model ID**: `gemini-2.5-flash-lite`

The system uses Google's Gemini 2.5 Flash Lite for all LLM operations:

#### Features Used:
- **Structured Output**: JSON schema-based extraction for reliable parsing
- **Low Temperature (0.1)**: Consistent, deterministic outputs
- **Large Context Window**: Handles lengthy CVs and job descriptions

#### Tasks Performed:
1. **CV Data Extraction**: Extract name, skills, experience, education
2. **Job Data Extraction**: Extract title, requirements, salary range
3. **Summary Generation**: Create search-optimized summaries
4. **Match Grading**: Generate reasoning for match scores

```typescript
// Example: Structured output configuration
config: {
  responseMimeType: 'application/json',
  responseSchema: zodToJsonSchema(CandidateExtractionSchema),
  temperature: 0.1,
}
```

### Text Embedding Model

**Model ID**: `text-embedding-004`

Google's latest embedding model for semantic search:

| Property | Value |
|----------|-------|
| Dimensions | 768 |
| Similarity Metric | Cosine |
| Normalization | Applied before storage |

#### Usage:
- Generate candidate summary embeddings
- Generate job summary embeddings
- Semantic similarity search queries

### RAG with Qdrant

**Qdrant** is used as the vector database for RAG implementation:

#### Collections:
1. **candidates**: Stores candidate embeddings with metadata
2. **jobs**: Stores job embeddings with metadata

#### Configuration:
```typescript
{
  host: 'localhost',
  port: 6333,
  embeddingDimensions: 768,
  distance: 'Cosine'
}
```

#### Payload Structure:
```typescript
// Candidate Payload
{
  candidateId: string,
  name: string,
  email: string,
  skills: string[],
  experienceYears: number,
  location: string,
  summary: string,
  createdAt: string
}
```

### Dual Search Strategy

The system combines two search methods for optimal results:

#### 1. SQL Search (PostgreSQL)
- Filters by required skills (JSONB queries)
- Filters by minimum experience years
- Supports fuzzy skill matching
- Configurable match percentage threshold

```sql
-- Simplified example of skill matching
SELECT * FROM candidates
WHERE (skill_match_count / total_skills) >= 0.3
  AND total_experience_years >= min_required
```

#### 2. Vector Search (Qdrant)
- Semantic similarity using embeddings
- Cosine similarity scoring
- Returns top-k most similar candidates

```typescript
// Vector search example
const results = await vectorService.searchCandidates(
  queryEmbedding,  // 768-dim job summary embedding
  limit: 20,       // Top 20 candidates
);
```

#### 3. Result Merging
- Candidates found in both searches = "Dual Match" (highest priority)
- Unique candidates from each search retained
- All candidates scored with sophisticated algorithm

### Sophisticated Scoring Algorithm

The matching score is calculated using multiple weighted factors:

| Factor | Weight | Description |
|--------|--------|-------------|
| **Skill Match** | 35% | Percentage of required/optional skills matched |
| **Skill Proficiency** | 15% | How well skill levels align with requirements |
| **Experience Match** | 20% | Years of experience vs. requirements |
| **Location Match** | 10% | Geographic alignment (remote-friendly) |
| **Vector Similarity** | 15% | Semantic similarity score from embeddings |
| **SQL Match Bonus** | 5% | Bonus for appearing in structured search |

#### Skill Matching Features:
- **Exact Matching**: Direct skill name comparison
- **Fuzzy Matching**: Handles variations (JS/JavaScript, Python/Py)
- **Abbreviation Support**: Common tech abbreviations
- **Levenshtein Distance**: Close spelling matches

#### Experience Scoring:
- **Perfect Match (0-3 years over)**: 100%
- **Slightly Overqualified (3-7 years)**: 70-90%
- **Significantly Overqualified (7+)**: 50-70%
- **Slightly Under (-2 years)**: 60-80%
- **Significantly Under**: 20-60%

---

## ğŸ“Š Dataset Description

For detailed dataset information, see [DATASET_DESCRIPTION.md](./DATASET_DESCRIPTION.md).

### Quick Overview:

#### Candidate Dataset (`Resume_Dataset/`)
- **24 professional categories** (Accountant, IT, Healthcare, etc.)
- **PDF format** resumes with real-world content
- **Structured extraction** into: name, skills, experience, education

#### Job Dataset (`Jobs Positions/`)
- **20 job descriptions** focused on accounting positions
- **PDF format** with standardized structure
- **Extracted fields**: title, requirements, salary, benefits

---

## ğŸš€ Setup Instructions

### Prerequisites

Before you begin, ensure you have the following installed:

| Requirement | Version | Purpose |
|-------------|---------|---------|
| **Node.js** | >= 18.x | Runtime environment |
| **pnpm** | >= 8.x | Package manager |
| **Docker** | Latest | Container runtime |
| **Docker Compose** | Latest | Service orchestration |

### Installation

#### Step 1: Clone the Repository
```bash
git clone <repository-url>
cd AIJobMatching
```

#### Step 2: Install Dependencies
```bash
pnpm install
```

#### Step 3: Get Google AI API Key
1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Sign in with your Google account
3. Click "Create API Key"
4. Copy the generated API key

### Configuration

#### Step 1: Create Environment File
```bash
# Windows
copy .env.example .env

# Linux/Mac
cp .env.example .env
```

#### Step 2: Configure Environment Variables
Edit `.env` with your settings:

```env
# =============================================================================
# Google AI Configuration (Required)
# =============================================================================
GEMINI_API_KEY=your_google_ai_api_key_here

# =============================================================================
# LLM Configuration
# =============================================================================
LLM_MODEL=gemini-2.5-flash-lite
EMBEDDING_MODEL=text-embedding-004

# =============================================================================
# Matching Configuration
# =============================================================================
MAX_CANDIDATES_RETURN=5
DUAL_MATCH_SCORE=100

# =============================================================================
# Database Configuration
# =============================================================================
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=job_matching

# =============================================================================
# Qdrant Configuration
# =============================================================================
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_CANDIDATES_COLLECTION=candidates
QDRANT_JOBS_COLLECTION=jobs
EMBEDDING_DIMENSIONS=768
```

### Running the Application

#### Option 1: Development Mode (Recommended)

```bash
# Step 1: Start Docker containers (PostgreSQL + Qdrant)
pnpm run docker:up

# Step 2: Wait for services to be healthy (~10 seconds)

# Step 3: Start the NestJS application
pnpm run start:dev
```

#### Option 2: All-in-One Command
```bash
pnpm run start:all
```

#### Option 3: Production Mode
```bash
# Build the application
pnpm run build

# Start in production mode
pnpm run start:prod
```

### Verifying Installation

1. **Application Health**: http://localhost:3000/api
2. **Swagger Documentation**: http://localhost:3000/docs
3. **Qdrant Dashboard**: http://localhost:6333/dashboard

### Stopping the Application

```bash
# Stop NestJS (Ctrl+C in terminal)

# Stop Docker containers
pnpm run docker:down

# Remove all data (clean slate)
pnpm run docker:clean
```

### Troubleshooting

#### Issue: Qdrant Collection Dimension Mismatch
If you've run the application before with different embedding dimensions:
```bash
# Option 1: Delete collections via Qdrant dashboard
# http://localhost:6333/dashboard -> Delete candidates & jobs collections

# Option 2: Reset all data
pnpm run docker:clean
pnpm run docker:up
```

#### Issue: Port Already in Use
```bash
# Check what's using the port (Windows)
netstat -ano | findstr :3000
netstat -ano | findstr :5432
netstat -ano | findstr :6333

# Kill the process or change ports in .env
```

#### Issue: API Key Invalid
Ensure your Google AI API key:
- Is active and has quota remaining
- Has access to Gemini 2.5 Flash Lite
- Is correctly copied without spaces

---

## ğŸ“š API Documentation

Access the interactive Swagger documentation at: http://localhost:3000/docs

### Candidate Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/candidate/load` | Upload a single CV PDF |
| `POST` | `/api/candidate/load_folder` | Process all CVs in a folder |
| `GET` | `/api/candidate` | List all candidates (paginated) |
| `GET` | `/api/candidate/:id` | Get candidate by ID |
| `DELETE` | `/api/candidate/:id` | Delete a candidate |

### Job Offer Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/job-offer/match` | Upload job PDF and find matches |
| `POST` | `/api/job-offer/match-path` | Match from server file path |
| `GET` | `/api/job-offer` | List all job offers (paginated) |
| `GET` | `/api/job-offer/:id` | Get job offer by ID |
| `DELETE` | `/api/job-offer/:id` | Delete a job offer |

### Example: Upload and Match

```bash
# 1. Upload CVs from a folder
curl -X POST http://localhost:3000/api/candidate/load_folder \
  -H "Content-Type: application/json" \
  -d '{"folderPath": "./Resume_Dataset/data/ACCOUNTANT"}'

# 2. Upload a job description and get matches
curl -X POST http://localhost:3000/api/job-offer/match \
  -F "file=@./Jobs Positions/Job_1_Senior_Accountant_Healthcare.pdf"
```

### Sample Response (Job Matching)

```json
{
  "success": true,
  "message": "Found 5 matching candidates",
  "job": {
    "id": "uuid-here",
    "title": "Senior Accountant â€“ Healthcare",
    "company": "Healthcare Corp",
    "requirements": [
      {"skill": "GAAP", "required": true, "minYearsExperience": 3},
      {"skill": "Excel", "required": true, "minYearsExperience": 2}
    ]
  },
  "candidates": [
    {
      "candidateId": "candidate-uuid",
      "name": "John Doe",
      "email": "john@example.com",
      "matchScore": 100,
      "matchSources": ["sql", "vector"],
      "matchDetails": {
        "sqlMatch": true,
        "vectorMatch": true,
        "vectorScore": 0.89,
        "skillScore": 85,
        "experienceScore": 90,
        "reasoning": "Excellent match. Skills: 4/5 required skills matched."
      },
      "skills": ["GAAP", "Excel", "QuickBooks", "SAP"],
      "experienceYears": 7.5
    }
  ],
  "searchMetadata": {
    "sqlMatchCount": 15,
    "vectorMatchCount": 12,
    "dualMatchCount": 5
  }
}
```

---

## ğŸ“ Project Structure

```
AIJobMatching/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                    # Application entry point
â”‚   â”œâ”€â”€ app.module.ts              # Root module
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                    # Agentic architecture
â”‚   â”‚   â”œâ”€â”€ agents.module.ts       # Agents module configuration
â”‚   â”‚   â”œâ”€â”€ orchestrator.agent.ts  # Central task coordinator
â”‚   â”‚   â”œâ”€â”€ candidate-ingestion.agent.ts  # CV processing agent
â”‚   â”‚   â”œâ”€â”€ job-processing.agent.ts       # Job matching agent
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/              # Shared AI services
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.service.ts     # Gemini LLM integration
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding.service.ts  # Embedding generation
â”‚   â”‚   â”‚   â””â”€â”€ pdf-parser.service.ts # PDF text extraction
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ tools/                 # Agent tools
â”‚   â”‚       â”œâ”€â”€ postgres-query.tool.ts  # SQL search tool
â”‚   â”‚       â”œâ”€â”€ vector-search.tool.ts   # Vector search tool
â”‚   â”‚       â””â”€â”€ matching-grade.tool.ts  # Scoring algorithm
â”‚   â”‚
â”‚   â”œâ”€â”€ candidate/                 # Candidate feature module
â”‚   â”‚   â”œâ”€â”€ candidate.module.ts
â”‚   â”‚   â”œâ”€â”€ candidate.controller.ts
â”‚   â”‚   â””â”€â”€ candidate.service.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ job-offer/                 # Job offer feature module
â”‚   â”‚   â”œâ”€â”€ job-offer.module.ts
â”‚   â”‚   â”œâ”€â”€ job-offer.controller.ts
â”‚   â”‚   â””â”€â”€ job-offer.service.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                  # Database configuration
â”‚   â”‚   â”œâ”€â”€ database.module.ts
â”‚   â”‚   â””â”€â”€ entities/
â”‚   â”‚       â”œâ”€â”€ candidate.entity.ts
â”‚   â”‚       â””â”€â”€ job.entity.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ vector/                    # Vector database module
â”‚   â”‚   â”œâ”€â”€ vector.module.ts
â”‚   â”‚   â””â”€â”€ vector.service.ts
â”‚   â”‚
â”‚   â””â”€â”€ common/                    # Shared code
â”‚       â”œâ”€â”€ dto/                   # Data Transfer Objects
â”‚       â””â”€â”€ interfaces/            # TypeScript interfaces
â”‚
â”œâ”€â”€ Jobs Positions/                # Sample job descriptions (20 PDFs)
â”œâ”€â”€ Resume_Dataset/                # Sample CVs (24 categories)
â”‚
â”œâ”€â”€ docker-compose.yml             # Docker services config
â”œâ”€â”€ package.json                   # Dependencies
â”œâ”€â”€ tsconfig.json                  # TypeScript config
â”œâ”€â”€ nest-cli.json                  # NestJS CLI config
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ DATASET_DESCRIPTION.md         # Dataset documentation
```

---

## ğŸ“¦ Deliverables

This project includes the following deliverables:

### 1. Source Code
- âœ… Clean, well-structured TypeScript code
- âœ… Comprehensive inline comments
- âœ… Modular architecture following NestJS best practices

### 2. Documentation
- âœ… **README.md**: Complete project documentation (this file)
- âœ… **DATASET_DESCRIPTION.md**: Detailed dataset documentation
- âœ… **Swagger/OpenAPI**: Interactive API documentation at `/docs`

### 3. Dataset
- âœ… **Resume Dataset**: 24 categories of professional CVs
- âœ… **Job Positions**: 20 accounting job descriptions

### 4. Models & Methods
- âœ… **LLM**: Google Gemini 2.5 Flash Lite for structured extraction
- âœ… **Embeddings**: Google text-embedding-004 (768 dimensions)
- âœ… **Vector Store**: Qdrant for RAG implementation
- âœ… **Database**: PostgreSQL for structured storage
- âœ… **Architecture**: Multi-agent system with orchestrator pattern

### 5. Infrastructure
- âœ… **Docker Compose**: Easy deployment with containerization
- âœ… **Environment Configuration**: Flexible configuration via `.env`

---

## ğŸ”§ Environment Variables Reference

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Application port | `3000` |
| `GEMINI_API_KEY` | Google AI API key | **Required** |
| `LLM_MODEL` | LLM model identifier | `gemini-2.5-flash-lite` |
| `EMBEDDING_MODEL` | Embedding model | `text-embedding-004` |
| `MAX_CANDIDATES_RETURN` | Max candidates returned | `5` |
| `DUAL_MATCH_SCORE` | Score for dual matches | `100` |
| `DB_HOST` | PostgreSQL host | `localhost` |
| `DB_PORT` | PostgreSQL port | `5432` |
| `DB_USER` | PostgreSQL user | `postgres` |
| `DB_PASSWORD` | PostgreSQL password | `postgres` |
| `DB_NAME` | PostgreSQL database | `job_matching` |
| `QDRANT_HOST` | Qdrant host | `localhost` |
| `QDRANT_PORT` | Qdrant port | `6333` |
| `EMBEDDING_DIMENSIONS` | Vector dimensions | `768` |

---

## ğŸ“¦ PNPM Scripts Reference

| Script | Description |
|--------|-------------|
| `pnpm run start:dev` | Start in development mode with hot reload |
| `pnpm run start:prod` | Start in production mode |
| `pnpm run start:all` | Start Docker + NestJS application |
| `pnpm run build` | Build the application |
| `pnpm run docker:up` | Start Docker containers |
| `pnpm run docker:down` | Stop Docker containers |
| `pnpm run docker:clean` | Stop containers and remove volumes |
| `pnpm run docker:logs` | View Docker logs |
| `pnpm run test` | Run tests |
| `pnpm run lint` | Run ESLint |

---

## ğŸ‘¥ Authors

**Group B** - AI Job Matching System Project

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgments

- Google AI for Gemini API access
- Qdrant team for the vector database
- NestJS community for the excellent framework
- Resume Dataset contributors

---

**Happy Matching! ğŸ¯**
